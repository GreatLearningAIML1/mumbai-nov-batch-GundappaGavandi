{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Computer Vision with CNN_R7_Project1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vAZQlqcqYGKS",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Activation, Reshape, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.python.keras import utils\n",
        "#from tensorflow.keras.utils import np_utils\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,CSVLogger\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np \n",
        "import pandas as pd \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqpA1MbWXKNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip3 install --upgrade pip\n",
        "#!pip3 install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gLqo0VXNYJft",
        "outputId": "f35bf6f3-ec74-46ea-e61b-8dc51121594b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iQdR6XZEYNuT",
        "colab": {}
      },
      "source": [
        "def classestoint(label):\n",
        "    label = label.strip()\n",
        "    if label == \"Black-grass\":  return 0\n",
        "    if label == \"Charlock\":  return 1\n",
        "    if label == \"Cleavers\":  return 2\n",
        "    if label == \"Common Chickweed\":  return 3\n",
        "    if label == \"Common wheat\":  return 4\n",
        "    if label == \"Fat Hen\":  return 5\n",
        "    if label == \"Loose Silky-bent\": return 6\n",
        "    if label == \"Maize\":  return 7\n",
        "    if label == \"Scentless Mayweed\": return 8\n",
        "    if label == \"Shepherds Purse\": return 9\n",
        "    if label == \"Small-flowered Cranesbill\": return 10\n",
        "    if label == \"Sugar beet\": return 11\n",
        "    print(\"Invalid Label\", label)\n",
        "    return 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JWGzLfOrYgI5",
        "colab": {}
      },
      "source": [
        "def inttoclasses(i):\n",
        "    if i == 0: return \"Black-grass\"\n",
        "    elif i == 1: return \"Charlock\"\n",
        "    elif i == 2: return \"Cleavers\"\n",
        "    elif i == 3: return \"Common Chickweed\"\n",
        "    elif i == 4: return \"Common wheat\"\n",
        "    elif i == 5: return \"Fat Hen\"\n",
        "    elif i == 6: return \"Loose Silky-bent\"\n",
        "    elif i == 7: return \"Maize\"\n",
        "    elif i == 8: return \"Scentless Mayweed\"\n",
        "    elif i == 9: return \"Shepherds Purse\"\n",
        "    elif i == 10: return \"Small-flowered Cranesbill\"\n",
        "    elif i == 11: return \"Sugar beet\"\n",
        "    print(\"Invalid class \", i)\n",
        "    return \"Invalid Class\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sJhHCJUiYkSM",
        "colab": {}
      },
      "source": [
        "train_dir=\"/content/gdrive/My Drive/GreatlakesPython16112018/AIML/plant-seedlings-classification/train\"\n",
        "test_dir=\"/content/gdrive/My Drive/GreatlakesPython16112018/AIML/plant-seedlings-classification/test\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EuM1hY2WYwcm",
        "colab": {}
      },
      "source": [
        "#1.Read the images and generate the train and test dataset (5 points)\n",
        "NUM_CLASSES = 12\n",
        "# we need images of same size so we convert them into the size\n",
        "WIDTH = 128\n",
        "HEIGHT = 128\n",
        "DEPTH = 3\n",
        "inputShape = (WIDTH, HEIGHT, DEPTH)\n",
        "# initialize number of epochs to train for, initial learning rate and batch size\n",
        "EPOCHS = 15\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "\n",
        "def readTrainData(train_dir):\n",
        "    data = []\n",
        "    labels = []\n",
        "    # loop over the input images\n",
        "    dirs = os.listdir(train_dir) \n",
        "    for dir in dirs:\n",
        "        absDirPath = os.path.join(os.path.sep,train_dir, dir)\n",
        "        images = os.listdir(absDirPath)\n",
        "        for imageFileName in images:\n",
        "            # load the image, pre-process it, and store it in the data list\n",
        "            imageFullPath = os.path.join(train_dir, dir, imageFileName)\n",
        "            img = load_img(imageFullPath)\n",
        "            arr = img_to_array(img)  # Numpy array with shape (233,233,3)\n",
        "            arr = cv2.resize(arr, (HEIGHT,WIDTH)) #Numpy array with shape (HEIGHT, WIDTH,3)\n",
        "            #print(arr.shape) \n",
        "            data.append(arr)\n",
        "            label = classestoint(dir)\n",
        "            labels.append(label)\n",
        "    return data, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wmNvbM0rZOT8",
        "colab": {}
      },
      "source": [
        "def createModel():\n",
        "    model = Sequential()\n",
        "    # first set of CONV => RELU => POOL layers\n",
        "    # The CONV  layer will learn 20 convolution filters, each of which are 5×5.\n",
        "    model.add(Conv2D(32, (3,3), input_shape=inputShape))\n",
        "    #model.add(BatchNormalization()) \n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    # second set of CONV => RELU => POOL layers\n",
        "    model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
        "    #model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "    #model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=500))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(units=12))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "    # use binary_crossentropy if there are two classes\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AwrZPDJ7ZWi7",
        "outputId": "d0db4192-4eff-4903-8330-8a86e1e9d9bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#2.Divide the data set into Train and validation data sets\n",
        "random.seed(10)\n",
        "#allLabels =  os.listdir(\"train_dir\")  # list of subdirectories and files\n",
        "print(\"Loading images...\")\n",
        "sys.stdout.flush()\n",
        "X, Y = readTrainData(train_dir)\n",
        "# scale the raw pixel intensities to the range [0, 1]\n",
        "X = np.array(X, dtype=\"float\") / 255.0\n",
        "Y = np.array(Y)\n",
        "# convert the labels from integers to vectors\n",
        "Y =  to_categorical(Y, num_classes=12)\n",
        "\n",
        "print(\"Partition data into 90:10...\")\n",
        "sys.stdout.flush()\n",
        "# partition the data into training and testing splits using 90% training and 10% for validation\n",
        "(trainX, valX, trainY, valY) = train_test_split(X,Y,test_size=0.1, random_state=10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading images...\n",
            "Partition data into 90:10...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PORmHWmUiZCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1j1UsDe-fQeF",
        "outputId": "05df0695-fa10-42ce-a50b-6fed15acaa8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#3. Initialize & build the model (10 points)\n",
        "#construct the image generator for data augmentation\n",
        "model = KerasClassifier(build_fn=createModel, verbose=0)\n",
        "print(\"Generating images...\")\n",
        "sys.stdout.flush()\n",
        "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, \\\n",
        "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\\\n",
        "    horizontal_flip=True, fill_mode=\"nearest\")\n",
        "# initialize the model\n",
        "print(\"compiling model...\")\n",
        "sys.stdout.flush()\n",
        "model = createModel()\n",
        "# train the network\n",
        "print(\"training network...\")\n",
        "sys.stdout.flush()\n",
        "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS), \\\n",
        "    validation_data=(valX, valY), \\\n",
        "    steps_per_epoch=len(trainX) // BS, epochs=EPOCHS, verbose=1)\n",
        "\n",
        "# save the model to disk\n",
        "print(\"Saving model to drive\")\n",
        "sys.stdout.flush()\n",
        "model.save(\"/content/gdrive/My Drive/plant-seedlings-classification/CNNmodel2\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating images...\n",
            "compiling model...\n",
            "training network...\n",
            "WARNING:tensorflow:From <ipython-input-26-3e0dfe3d3b7b>:12: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-3e0dfe3d3b7b>:12: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train for 134 steps, validate on 479 samples\n",
            "Epoch 1/15\n",
            "134/134 [==============================] - 21s 159ms/step - loss: 2.2268 - accuracy: 0.2269 - val_loss: 1.7338 - val_accuracy: 0.3862\n",
            "Epoch 2/15\n",
            "134/134 [==============================] - 14s 106ms/step - loss: 1.6249 - accuracy: 0.4164 - val_loss: 1.2576 - val_accuracy: 0.5908\n",
            "Epoch 3/15\n",
            "134/134 [==============================] - 14s 108ms/step - loss: 1.3167 - accuracy: 0.5380 - val_loss: 1.1359 - val_accuracy: 0.6075\n",
            "Epoch 4/15\n",
            "134/134 [==============================] - 14s 108ms/step - loss: 1.1253 - accuracy: 0.6126 - val_loss: 0.9716 - val_accuracy: 0.6952\n",
            "Epoch 5/15\n",
            "134/134 [==============================] - 15s 109ms/step - loss: 1.0044 - accuracy: 0.6587 - val_loss: 0.8125 - val_accuracy: 0.7182\n",
            "Epoch 6/15\n",
            "134/134 [==============================] - 14s 108ms/step - loss: 0.8659 - accuracy: 0.7046 - val_loss: 0.9179 - val_accuracy: 0.6785\n",
            "Epoch 7/15\n",
            "134/134 [==============================] - 14s 107ms/step - loss: 0.8174 - accuracy: 0.7226 - val_loss: 0.7386 - val_accuracy: 0.7203\n",
            "Epoch 8/15\n",
            "134/134 [==============================] - 14s 107ms/step - loss: 0.6959 - accuracy: 0.7654 - val_loss: 0.5408 - val_accuracy: 0.8205\n",
            "Epoch 9/15\n",
            "134/134 [==============================] - 14s 108ms/step - loss: 0.6581 - accuracy: 0.7668 - val_loss: 0.6889 - val_accuracy: 0.7641\n",
            "Epoch 10/15\n",
            "134/134 [==============================] - 14s 107ms/step - loss: 0.6380 - accuracy: 0.7775 - val_loss: 0.6316 - val_accuracy: 0.7662\n",
            "Epoch 11/15\n",
            "134/134 [==============================] - 14s 108ms/step - loss: 0.5953 - accuracy: 0.7972 - val_loss: 0.4597 - val_accuracy: 0.8455\n",
            "Epoch 12/15\n",
            "134/134 [==============================] - 14s 106ms/step - loss: 0.5718 - accuracy: 0.8044 - val_loss: 0.4396 - val_accuracy: 0.8580\n",
            "Epoch 13/15\n",
            "134/134 [==============================] - 14s 107ms/step - loss: 0.5360 - accuracy: 0.8182 - val_loss: 0.4702 - val_accuracy: 0.8455\n",
            "Epoch 14/15\n",
            "134/134 [==============================] - 14s 106ms/step - loss: 0.5031 - accuracy: 0.8241 - val_loss: 0.4184 - val_accuracy: 0.8622\n",
            "Epoch 15/15\n",
            "134/134 [==============================] - 14s 106ms/step - loss: 0.4816 - accuracy: 0.8374 - val_loss: 0.4322 - val_accuracy: 0.8434\n",
            "Saving model to drive\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/plant-seedlings-classification/CNNmodel2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/plant-seedlings-classification/CNNmodel2/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Q0DaDlmoSFZ",
        "outputId": "0271101c-ad88-4cc8-8628-09a7b903d3d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "model.evaluate(trainX,trainY)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4307/4307 [==============================] - 1s 314us/sample - loss: 0.3155 - accuracy: 0.8823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.31548085732639375, 0.88228464]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pWUt2FfCoXRG",
        "outputId": "dc7d7027-236c-4e29-f9b6-46ded06c8c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(valX,valY)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "479/479 [==============================] - 0s 337us/sample - loss: 0.4322 - accuracy: 0.8434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.43218297749322243, 0.8434238]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YlCGFNCiFTNu",
        "outputId": "a7e2f296-7ffc-4541-ca15-da663026c3b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "y_pred = model.predict(valX)\n",
        "y_class = np.argmax(y_pred, axis = 1) \n",
        "y_check = np.argmax(valY, axis = 1) \n",
        "\n",
        "cmatrix = confusion_matrix(y_check, y_class)\n",
        "print(cmatrix)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[12  0  0  0  1  3 11  0  0  0  0  0]\n",
            " [ 0 38  1  0  0  1  0  1  0  0  2  1]\n",
            " [ 0  1 22  0  1  1  0  0  1  0  1  0]\n",
            " [ 0  0  1 54  0  0  0  0  1  0  0  1]\n",
            " [ 2  0  0  0 17  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  1  0 46  1  1  0  1  1  2]\n",
            " [15  0  0  0  0  1 50  0  1  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 19  0  0  0  0]\n",
            " [ 4  0  0  1  0  0  0  0 51  1  0  1]\n",
            " [ 0  0  0  2  1  0  0  0  3 11  0  0]\n",
            " [ 0  1  0  0  0  0  0  2  0  0 48  0]\n",
            " [ 0  0  1  0  1  0  0  2  0  0  0 36]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y_b-wEcfezLk",
        "colab": {}
      },
      "source": [
        " def readTestData(test_dir):\n",
        "    data = []\n",
        "    filenames = []\n",
        "    # loop over the input images\n",
        "    images = os.listdir(test_dir)\n",
        "    for imageFileName in images:\n",
        "        # load the image, pre-process it, and store it in the data list\n",
        "        imageFullPath = os.path.join(test_dir, imageFileName)\n",
        "        #print(imageFullPath)\n",
        "        img = load_img(imageFullPath)\n",
        "        arr = img_to_array(img)  # Numpy array with shape (...,..,3)\n",
        "        arr = cv2.resize(arr, (HEIGHT,WIDTH)) \n",
        "        data.append(arr)\n",
        "        filenames.append(imageFileName)\n",
        "    return data, filenames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PzQc4YmdheYC",
        "outputId": "b1b637a5-26f4-4a1e-a046-4d1b674945fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# read test data and find its classification\n",
        "testX, filenames = readTestData(test_dir)\n",
        "# scale the raw pixel intensities to the range [0, 1]\n",
        "testX = np.array(testX, dtype=\"float\") / 255.0\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "mymodel = load_model('/content/gdrive/My Drive/plant-seedlings-classification/CNNmodel2')\n",
        "yFit = mymodel.predict(testX, batch_size=10, verbose=1)\n",
        "print(yFit) \n",
        "print(type(yFit)) # numpy.ndarray\n",
        "print(type(filenames)) # list\n",
        "\n",
        "import csv  \n",
        "with open('/content/gdrive/My Drive/plant-seedlings-classification/output.csv', 'w', newline='') as csvfile:\n",
        "    fieldnames = ['file', 'species']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for index, file in enumerate(filenames):\n",
        "        classesProbs = yFit[index]\n",
        "        maxIdx = 0\n",
        "        maxProb = 0;\n",
        "        for idx in range(0,11):\n",
        "            if(classesProbs[idx] > maxProb):\n",
        "                maxIdx = idx\n",
        "                maxProb = classesProbs[idx]\n",
        "        writer.writerow({'file': file, 'species': inttoclasses(maxIdx)})\n",
        "print(\"Writing complete\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "803/803 [==============================] - 0s 500us/sample\n",
            "[[4.51067194e-07 2.71980093e-06 1.54198042e-05 ... 2.10523795e-04\n",
            "  9.97199178e-01 1.34445843e-03]\n",
            " [4.46475060e-05 2.19026138e-03 3.34457546e-01 ... 4.40017584e-06\n",
            "  9.88521697e-06 6.46371841e-01]\n",
            " [1.53799547e-07 1.20065236e-09 1.70484514e-12 ... 1.37563029e-06\n",
            "  2.23425695e-10 2.14625260e-07]\n",
            " ...\n",
            " [1.91536937e-02 8.61917382e-09 2.98625731e-04 ... 4.18353442e-11\n",
            "  3.36046675e-08 2.55432724e-06]\n",
            " [2.12368650e-10 9.68420208e-01 3.03717721e-02 ... 1.14208315e-05\n",
            "  1.11223594e-03 2.38818193e-05]\n",
            " [2.96728399e-06 2.45801033e-03 1.80157344e-03 ... 4.74299986e-06\n",
            "  1.99434135e-06 9.94423091e-01]]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "Writing complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GhRSb9tYjjyq",
        "colab": {}
      },
      "source": [
        "#output.csv gives 83.74% score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "51iim5fEHpeb",
        "colab": {}
      },
      "source": [
        "def Model():\n",
        "    model = Sequential()\n",
        "    # first set of CONV => RELU => POOL layers\n",
        "    # The CONV  layer will learn 20 convolution filters, each of which are 5×5.\n",
        "    model.add(Conv2D(32, (3,3), input_shape=inputShape))\n",
        "    #model.add(BatchNormalization()) \n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    # second set of CONV => RELU => POOL layers\n",
        "    model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
        "    #model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Conv2D(128, (3,3), padding=\"same\"))\n",
        "    #model.add(BatchNormalization())\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=500))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Dense(units=12))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "    # use binary_crossentropy if there are two classes\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pjVMYc5sIIv1",
        "outputId": "baa95c0c-092e-4ccc-9609-38a59aa4ed05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "#4. Optimize the model (8 points)\n",
        "\n",
        "#construct the image generator for data augmentation\n",
        "model = KerasClassifier(build_fn=Model, verbose=0)\n",
        "print(\"Generating images...\")\n",
        "sys.stdout.flush()\n",
        "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, \\\n",
        "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\\\n",
        "    horizontal_flip=True, fill_mode=\"nearest\")\n",
        "# initialize the model\n",
        "print(\"compiling model...\")\n",
        "sys.stdout.flush()\n",
        "model = Model()\n",
        "# train the network\n",
        "print(\"training network...\")\n",
        "sys.stdout.flush()\n",
        "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS), \\\n",
        "    validation_data=(valX, valY), \\\n",
        "    steps_per_epoch=len(trainX) // BS, epochs=EPOCHS, verbose=1)\n",
        "\n",
        "# save the model to disk\n",
        "print(\"Saving model to drive\")\n",
        "sys.stdout.flush()\n",
        "model.save(\"/content/gdrive/My Drive/plant-seedlings-classification/CNNmodel_opt\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating images...\n",
            "compiling model...\n",
            "training network...\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train for 134 steps, validate on 479 samples\n",
            "Epoch 1/15\n",
            "134/134 [==============================] - 14s 107ms/step - loss: 2.0013 - accuracy: 0.3125 - val_loss: 1.4846 - val_accuracy: 0.5073\n",
            "Epoch 2/15\n",
            "134/134 [==============================] - 14s 104ms/step - loss: 1.4519 - accuracy: 0.4978 - val_loss: 1.1070 - val_accuracy: 0.6701\n",
            "Epoch 3/15\n",
            "134/134 [==============================] - 14s 105ms/step - loss: 1.2105 - accuracy: 0.5843 - val_loss: 1.0730 - val_accuracy: 0.6263\n",
            "Epoch 4/15\n",
            "134/134 [==============================] - 14s 105ms/step - loss: 1.0352 - accuracy: 0.6510 - val_loss: 0.7721 - val_accuracy: 0.7578\n",
            "Epoch 5/15\n",
            "134/134 [==============================] - 14s 105ms/step - loss: 0.8995 - accuracy: 0.6980 - val_loss: 0.7265 - val_accuracy: 0.7766\n",
            "Epoch 6/15\n",
            "134/134 [==============================] - 14s 105ms/step - loss: 0.8115 - accuracy: 0.7284 - val_loss: 0.6252 - val_accuracy: 0.7683\n",
            "Epoch 7/15\n",
            "134/134 [==============================] - 14s 104ms/step - loss: 0.7276 - accuracy: 0.7565 - val_loss: 0.5910 - val_accuracy: 0.7787\n",
            "Epoch 8/15\n",
            "134/134 [==============================] - 14s 105ms/step - loss: 0.6476 - accuracy: 0.7815 - val_loss: 0.5393 - val_accuracy: 0.8225\n",
            "Epoch 9/15\n",
            "134/134 [==============================] - 14s 105ms/step - loss: 0.5893 - accuracy: 0.7970 - val_loss: 0.5843 - val_accuracy: 0.7912\n",
            "Epoch 10/15\n",
            "134/134 [==============================] - 14s 104ms/step - loss: 0.5580 - accuracy: 0.8094 - val_loss: 0.5004 - val_accuracy: 0.8372\n",
            "Epoch 11/15\n",
            "134/134 [==============================] - 14s 104ms/step - loss: 0.5159 - accuracy: 0.8211 - val_loss: 0.4361 - val_accuracy: 0.8434\n",
            "Epoch 12/15\n",
            "134/134 [==============================] - 14s 104ms/step - loss: 0.4982 - accuracy: 0.8262 - val_loss: 0.5521 - val_accuracy: 0.7787\n",
            "Epoch 13/15\n",
            "134/134 [==============================] - 14s 105ms/step - loss: 0.4856 - accuracy: 0.8365 - val_loss: 0.4239 - val_accuracy: 0.8727\n",
            "Epoch 14/15\n",
            "134/134 [==============================] - 14s 106ms/step - loss: 0.4578 - accuracy: 0.8426 - val_loss: 0.4338 - val_accuracy: 0.8539\n",
            "Epoch 15/15\n",
            "134/134 [==============================] - 14s 105ms/step - loss: 0.4340 - accuracy: 0.8517 - val_loss: 0.3811 - val_accuracy: 0.8643\n",
            "Saving model to drive\n",
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/plant-seedlings-classification/CNNmodel_opt/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/plant-seedlings-classification/CNNmodel_opt/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ILlIIrJbIdC3",
        "outputId": "b50b9d78-dbc0-49d0-ad19-a99e26f752e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#5. Predict the accuracy for both train and validation data (7 points)\n",
        "model.evaluate(trainX,trainY)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4307/4307 [==============================] - 1s 308us/sample - loss: 0.2826 - accuracy: 0.8964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28258022080587075, 0.89644766]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4NIYTdU-MKmW",
        "outputId": "80e8bf1a-bb3c-44f7-86eb-ae3d8bc85a2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(valX,valY)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "479/479 [==============================] - 0s 315us/sample - loss: 0.3811 - accuracy: 0.8643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38108332620035384, 0.8643006]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ms8bZIlLMSqD",
        "outputId": "ebbf8e0f-3c6b-4ef0-8ec8-5a5d44db0a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "y_pred = model.predict(valX)\n",
        "y_class = np.argmax(y_pred, axis = 1) \n",
        "y_check = np.argmax(valY, axis = 1) \n",
        "\n",
        "cmatrix = confusion_matrix(y_check, y_class)\n",
        "print(cmatrix)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 8  0  0  0  2  0 15  0  2  0  0  0]\n",
            " [ 0 41  1  0  0  2  0  0  0  0  0  0]\n",
            " [ 0  3 22  0  0  2  0  0  0  0  0  0]\n",
            " [ 0  0  0 49  0  0  0  0  2  4  1  1]\n",
            " [ 0  0  0  0 19  0  0  0  0  0  0  0]\n",
            " [ 0  3  0  1  0 49  0  0  0  0  0  0]\n",
            " [10  0  0  0  1  3 53  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 19  0  0  0  0]\n",
            " [ 1  0  0  0  0  0  0  0 55  2  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  2 15  0  0]\n",
            " [ 0  1  0  0  0  0  0  1  0  0 49  0]\n",
            " [ 0  1  1  0  2  0  0  1  0  0  0 35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1a_cZGuCShoy",
        "outputId": "de702d05-9973-4569-b83f-095eda96ecdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# read test data and find its classification\n",
        "testX, filenames = readTestData(test_dir)\n",
        "# scale the raw pixel intensities to the range [0, 1]\n",
        "testX = np.array(testX, dtype=\"float\") / 255.0\n",
        "\n",
        "mymodel = load_model('/content/gdrive/My Drive/plant-seedlings-classification/CNNmodel_opt')\n",
        "yFit = mymodel.predict(testX, batch_size=10, verbose=1)\n",
        "print(yFit) \n",
        "print(type(yFit)) # numpy.ndarray\n",
        "print(type(filenames)) # list\n",
        "\n",
        "import csv  \n",
        "with open('/content/gdrive/My Drive/plant-seedlings-classification/output_opt.csv', 'w', newline='') as csvfile:\n",
        "    fieldnames = ['file', 'species']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for index, file in enumerate(filenames):\n",
        "        classesProbs = yFit[index]\n",
        "        maxIdx = 0\n",
        "        maxProb = 0;\n",
        "        for idx in range(0,11):\n",
        "            if(classesProbs[idx] > maxProb):\n",
        "                maxIdx = idx\n",
        "                maxProb = classesProbs[idx]\n",
        "        writer.writerow({'file': file, 'species': inttoclasses(maxIdx)})\n",
        "print(\"Writing complete\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "803/803 [==============================] - 0s 439us/sample\n",
            "[[1.3980251e-06 9.1038282e-06 4.3932501e-05 ... 1.6125438e-03\n",
            "  9.9128145e-01 5.4049678e-04]\n",
            " [7.1336013e-05 1.8153027e-02 2.2554061e-01 ... 8.8442393e-06\n",
            "  3.0454841e-05 7.3736489e-01]\n",
            " [3.3971727e-08 3.1150378e-08 6.6404715e-10 ... 8.9273199e-05\n",
            "  1.1467404e-09 1.0123879e-05]\n",
            " ...\n",
            " [3.6933343e-03 8.6262162e-09 5.1945392e-03 ... 2.8926053e-11\n",
            "  1.6969562e-07 1.0731575e-07]\n",
            " [9.4486557e-11 9.9547261e-01 4.3043843e-03 ... 1.5502539e-05\n",
            "  1.4292472e-04 2.4522963e-06]\n",
            " [1.8020959e-06 8.3979107e-03 3.0307227e-03 ... 2.2125347e-05\n",
            "  1.3609038e-05 9.8274833e-01]]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "Writing complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L9Koex_XS0j0",
        "colab": {}
      },
      "source": [
        "#output.csv gives 85.17% score"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}